{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab07-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMyfput2QTFi92/bUnp7xF+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kookeej/DILAB/blob/main/7.1-7.7/lab07-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XozHkZ2a-rhg"
      },
      "source": [
        "Lab07-1 - Tips\n",
        "===\n",
        "여러가지 tip들에 대해 다뤄보는 시간이다.\n",
        "\n",
        "## 목차\n",
        "* Maximum Likelihood Estimation\n",
        "* Overfitting and Regularization\n",
        "* Training and Test Dataset\n",
        "* Learning Rate\n",
        "* Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0En0ICHdzea"
      },
      "source": [
        "# 1. Maximum Likelihood Estimation (MLE)\n",
        "예를 들어 압정 앞/뒷면이 나올 확률을 살펴보자. 앞면, 그리고 뒷면 두 가지 경우만 존재하므로 이항분포, 또는 베르누이 분포라고도 한다. 따라서 ```Binary classification```을 수행하면 된다.     \n",
        "MLE는 말 그대로 likelihood가 최대가 되는 지점을 찾는 것이다. 만약 최대가 되는 theta값이 0.27이라면, Observation을 가장 잘 설명하는 theta는 0.27이다.     \n",
        "즉, Maximum likelihood extimation은 observation을 가장 잘 설명하는 theta를 찾는 과정이다.    \n",
        "관찰한 data를 가장 잘 설명하는 어떤 확률분포함수의 파라미터를 찾아내는 과정이다.    \n",
        "\n",
        "* Gradient descent를 통해 최적화한다.\n",
        "* 하지만 MLE의 경우 overfitting을 피할 수 없다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDJS0xNCfIq-"
      },
      "source": [
        "# 2. Overfitting\n",
        "* MLE를 통해 model을 얻으면 과하게 구불거리는 곡선이 나온다. 이를 ```overfitting```이라고 한다. 우리는 이 overfitting을 최소화해야한다. overfitting을 최소화하는 방법에는 Training set과 Test set을 나누는 방법이 있다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32vHIAtOAQ4P"
      },
      "source": [
        "# 3. Training and Test Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otCk8axj-Sfx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMuMHGsPN40z",
        "outputId": "5f8b2f8a-f39c-4e9c-a9ec-3e6ecfee139d"
      },
      "source": [
        "torch.manual_seed(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f651da50ad0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX_2-v8cN_Yy"
      },
      "source": [
        "* Training set과 Test set을 나눠준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC7OxjM_N-Xi"
      },
      "source": [
        "x_train = torch.FloatTensor([[1, 2, 1],\n",
        "                             [1, 3, 2],\n",
        "                             [1, 3, 4,],\n",
        "                             [1, 5, 5],\n",
        "                             [1, 7, 5],\n",
        "                             [1, 2, 5],\n",
        "                             [1, 6, 6],\n",
        "                             [1, 7, 7]])\n",
        "y_train = torch.LongTensor([2, 2, 2, 1, 1, 1, 0, 0])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okOUDdB7OT_y"
      },
      "source": [
        "x_test = torch.FloatTensor([[2, 1, 1], [3, 1, 2], [3, 3, 4]])\n",
        "y_test = torch.LongTensor([2, 2, 2])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGd_Os_9Oqpw"
      },
      "source": [
        "* |x_train| = (m, 3)\n",
        "* |y_train| = (m,)\n",
        "* |x_test| = (m`, 3)\n",
        "* [y_test| = (m`, )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lasEUVouO8_y"
      },
      "source": [
        "* Model을 설계해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myRY3syKO76C"
      },
      "source": [
        "class SoftmaxClassifierModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3, 3)       # 3->3\n",
        "    def forward(self, x):        \n",
        "        return self.linear(x)               # |x| = (m, 3) -> (m, 3)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZGncrEoPV-i"
      },
      "source": [
        "model = SoftmaxClassifierModel()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-qlcxYjPd1q"
      },
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oGOdpAFP1Sw"
      },
      "source": [
        "* Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPxq2xk5P3Gq"
      },
      "source": [
        "def train(model, optimizer, x_train, y_train):\n",
        "    nb_epochs = 20\n",
        "    for epoch in range(nb_epochs):\n",
        "        prediction = model(x_train)\n",
        "        cost = F.cross_entropy(prediction, y_train)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrkNMYezQfpz"
      },
      "source": [
        "* Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTapsf9gQVZ6"
      },
      "source": [
        "def test(model, optimizer, x_test, y_test):\n",
        "    prediction = model(x_test)\n",
        "    predicted_classes = prediction.max(1)[1]\n",
        "    correct_count = (predicted_classes == y_test).sum().item()\n",
        "    cost = F.cross_entropy(prediction, y_test)\n",
        "\n",
        "    print('Accuracy: {}% Cost: {:.6f}'.format(\n",
        "        correct_count / len(y_test) * 100, cost.item()\n",
        "    ))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iTLXZ8WUfYn"
      },
      "source": [
        "* Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6K54UV8tRMMS",
        "outputId": "b6f7a416-0510-4845-868d-d52dd59c69e1"
      },
      "source": [
        "train(model, optimizer, x_train, y_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/20 Cost: 2.203667\n",
            "Epoch    1/20 Cost: 1.199645\n",
            "Epoch    2/20 Cost: 1.142985\n",
            "Epoch    3/20 Cost: 1.117769\n",
            "Epoch    4/20 Cost: 1.100901\n",
            "Epoch    5/20 Cost: 1.089523\n",
            "Epoch    6/20 Cost: 1.079872\n",
            "Epoch    7/20 Cost: 1.071320\n",
            "Epoch    8/20 Cost: 1.063325\n",
            "Epoch    9/20 Cost: 1.055720\n",
            "Epoch   10/20 Cost: 1.048378\n",
            "Epoch   11/20 Cost: 1.041245\n",
            "Epoch   12/20 Cost: 1.034285\n",
            "Epoch   13/20 Cost: 1.027478\n",
            "Epoch   14/20 Cost: 1.020813\n",
            "Epoch   15/20 Cost: 1.014279\n",
            "Epoch   16/20 Cost: 1.007872\n",
            "Epoch   17/20 Cost: 1.001586\n",
            "Epoch   18/20 Cost: 0.995419\n",
            "Epoch   19/20 Cost: 0.989365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV3gSlfCUkgA"
      },
      "source": [
        "MLE를 통해서 가장 적절한 ```theta```값을 찾는 과정이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9ngUijwUafp",
        "outputId": "601c534f-c1fe-4e69-cc0b-03e10cd12228"
      },
      "source": [
        "test(model, optimizer, x_test, y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.0% Cost: 1.425844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD4VAgs2Ugxo"
      },
      "source": [
        "하지만 test set에 대해서 똑같이 수행해보았을 때, cost값이 높아진 것을 확인할 수 있다. 따라서 어떤 epoch 시점에서 pick을 해봤을 때는 이미 overfitting이 발생한 상태이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCG9-tI3VIYI"
      },
      "source": [
        "# 4. Learning Rate\n",
        "```learning rate```는 학습 속도를 조절한다.\n",
        "## 4.1. Overshooting\n",
        "```learning rate```가 너무 크면 ```overshooting```이 발생한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQDWMnW1Vp2Q",
        "outputId": "baf8d8b4-929b-4879-b996-46bee50352a9"
      },
      "source": [
        "model = SoftmaxClassifierModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e5)\n",
        "train(model, optimizer, x_train, y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/20 Cost: 1.280268\n",
            "Epoch    1/20 Cost: 976950.750000\n",
            "Epoch    2/20 Cost: 1279135.250000\n",
            "Epoch    3/20 Cost: 1198378.875000\n",
            "Epoch    4/20 Cost: 1098825.750000\n",
            "Epoch    5/20 Cost: 1968197.750000\n",
            "Epoch    6/20 Cost: 284763.250000\n",
            "Epoch    7/20 Cost: 1532260.250000\n",
            "Epoch    8/20 Cost: 1651503.750000\n",
            "Epoch    9/20 Cost: 521878.593750\n",
            "Epoch   10/20 Cost: 1397263.250000\n",
            "Epoch   11/20 Cost: 750986.375000\n",
            "Epoch   12/20 Cost: 918691.375000\n",
            "Epoch   13/20 Cost: 1487888.250000\n",
            "Epoch   14/20 Cost: 1582260.250000\n",
            "Epoch   15/20 Cost: 685818.125000\n",
            "Epoch   16/20 Cost: 1140048.875000\n",
            "Epoch   17/20 Cost: 940566.375000\n",
            "Epoch   18/20 Cost: 931638.250000\n",
            "Epoch   19/20 Cost: 1971322.750000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWrNDu68V7kA"
      },
      "source": [
        "```learning rate```가 너무 크기 때문에 cost값이 발산해버리는 문제가 발생했다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onqj8NKBWCkA"
      },
      "source": [
        "## 4.2. Too small \n",
        "```learning rate```가 너무 작으면 학습 속도가 너무 느려지기 때문에 cost가 거의 줄어들지 않는다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR4MWHv3WTPo",
        "outputId": "c964730b-0e3d-48cc-b191-c746e0ac9c2a"
      },
      "source": [
        "model = SoftmaxClassifierModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-10)\n",
        "train(model, optimizer, x_train, y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/20 Cost: 3.187324\n",
            "Epoch    1/20 Cost: 3.187324\n",
            "Epoch    2/20 Cost: 3.187324\n",
            "Epoch    3/20 Cost: 3.187324\n",
            "Epoch    4/20 Cost: 3.187324\n",
            "Epoch    5/20 Cost: 3.187324\n",
            "Epoch    6/20 Cost: 3.187324\n",
            "Epoch    7/20 Cost: 3.187324\n",
            "Epoch    8/20 Cost: 3.187324\n",
            "Epoch    9/20 Cost: 3.187324\n",
            "Epoch   10/20 Cost: 3.187324\n",
            "Epoch   11/20 Cost: 3.187324\n",
            "Epoch   12/20 Cost: 3.187324\n",
            "Epoch   13/20 Cost: 3.187324\n",
            "Epoch   14/20 Cost: 3.187324\n",
            "Epoch   15/20 Cost: 3.187324\n",
            "Epoch   16/20 Cost: 3.187324\n",
            "Epoch   17/20 Cost: 3.187324\n",
            "Epoch   18/20 Cost: 3.187324\n",
            "Epoch   19/20 Cost: 3.187324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IAod19TWV6A"
      },
      "source": [
        "cost값이 거의 줄어들지 않는 것을 확인할 수 있다. 따라서 적절한 learning rate을 설정하는 것이 중요하다는 것을 알 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw0XG2LOWq5S",
        "outputId": "af049f95-95a3-48f0-cf6b-48948b2e6e10"
      },
      "source": [
        "model = SoftmaxClassifierModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-1)\n",
        "train(model, optimizer, x_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/20 Cost: 1.341574\n",
            "Epoch    1/20 Cost: 1.198802\n",
            "Epoch    2/20 Cost: 1.150877\n",
            "Epoch    3/20 Cost: 1.131977\n",
            "Epoch    4/20 Cost: 1.116242\n",
            "Epoch    5/20 Cost: 1.102514\n",
            "Epoch    6/20 Cost: 1.089676\n",
            "Epoch    7/20 Cost: 1.077479\n",
            "Epoch    8/20 Cost: 1.065775\n",
            "Epoch    9/20 Cost: 1.054511\n",
            "Epoch   10/20 Cost: 1.043655\n",
            "Epoch   11/20 Cost: 1.033187\n",
            "Epoch   12/20 Cost: 1.023091\n",
            "Epoch   13/20 Cost: 1.013356\n",
            "Epoch   14/20 Cost: 1.003968\n",
            "Epoch   15/20 Cost: 0.994917\n",
            "Epoch   16/20 Cost: 0.986189\n",
            "Epoch   17/20 Cost: 0.977775\n",
            "Epoch   18/20 Cost: 0.969661\n",
            "Epoch   19/20 Cost: 0.961836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpHD-tcIWt9g"
      },
      "source": [
        "적절한 learning rate을 설정했을 때 cost값이 제대로 줄어드는 것을 알 수 있다. 보통 0.01로 초기화한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqiK2E0BW9Wx"
      },
      "source": [
        "# 5. Data Preprocessing\n",
        "데이터 전처리를 통해 데이터를 좀 더 학습하기 쉽도록 바꿔주는 것은 매우 중요하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK2S8IgNXBTg"
      },
      "source": [
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05qJ34OcXjs6"
      },
      "source": [
        "데이터 전처리를 해주게 되면 훨씬 더 학습이 수월해진다.     \n",
        "데이터를 zero-center하고 normalize한다.    \n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFsAAAAeCAYAAABDo2JGAAACcklEQVRoBe2YMU7FMAyGvSIhwcrGwo64AEwMLHAEjsDCDEdg4AAcgSNwA7gB3AT0SfFTXpU4aZuGtqklq0maxPFvx3Yrsi46FZF3EbkTkWfHU2l4JSL3bnOe9JsjgAbw4x6aH4jIdYRj27x4AH+JCIZujlD6w9A6ZIgjEXmMMIYIEQBD5yLy49rdh87pjq+mz5VWJUPeHRrrqzx7YFCeeDgc2jc01lfWLOcD8psHgLb9w2os98eGtNkHbyYvPHhydS9A5jxws1QKbDw5FaMxRNNg+0ltjMdZOUH3JTekDKJzs58IXkrZo7E8W7nAREIESTFFJWTtyUBwLBPvTZxBh7PmeGSJo2IMckZRWlISIF6TzGoQcpCXJEKCxprUlSEJxAhD6D6xObXG8WjOij5TEvri0eSGJAE0gV0LfxbRjpEFJpbNVQ65TwleZWYHpO+RVw6QL2MWCowDNp5nsQX2oUvS7DM3PgvouxsCqN+RFQYxq1Yy4uAX7syce278ukM20CA0cOCsAB9YzxBeaMXz7jJkchMstsqtk8StsG7M1O9uusr6fYRnB3l/oddmPdc5lzAON8HirKSTK/A/5xE6br0fKij/6QCzPCp25uIFfUzQEsfxQrxKgQV8+lZSiulJSLAqmNi6bbwnAgCNgYYYqaeotqcDNLF6iUCTpwh9sH/D27boBNqTeHESSD/mXHd7lESA2+j/SMOrQ1UUY2qQkvKb2ksLA5TWoqApAGoqC8CEEUDnqxdP7xJz8Gqt1Lrvt35hBAgvgL5RBQS2j7QKICOCELOaXwWVMBsshhp8zE+5wYJbXLj9eqhgdbyZCqXYF/EfWSCmcvv4+ewAAAAASUVORK5CYII=)\n",
        "     \n",
        "\n",
        "여기서 σ는 standard deviation, μ는 평균값이다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kL0y2ddYLWA",
        "outputId": "811aa981-2ecf-49a1-9798-91464ff2eb93"
      },
      "source": [
        "mu = x_train.mean(dim=0)\n",
        "sigma = x_train.std(dim=0)\n",
        "norm_x_train = (x_train - mu) / sigma\n",
        "print(norm_x_train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.0674, -0.3758, -0.8398],\n",
            "        [ 0.7418,  0.2778,  0.5863],\n",
            "        [ 0.3799,  0.5229,  0.3486],\n",
            "        [ 1.0132,  1.0948,  1.1409],\n",
            "        [-1.0674, -1.5197, -1.2360]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEB1k3ueYdyu"
      },
      "source": [
        "즉, 단위를 통일하는 표준화를 한다???\n",
        "training set이 정규분포가 된다???? (질문)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33ZKfIeQY4l3"
      },
      "source": [
        "* Training with Preprocessed Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSQtsmY8Y7PX"
      },
      "source": [
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(3, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NIYbYbLZJ9Q"
      },
      "source": [
        "model = MultivariateLinearRegressionModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqOIcfNTZYag"
      },
      "source": [
        "def train(model, optimizer, x_train, y_train):\n",
        "    nb_epochs = 20\n",
        "    for epoch in range(nb_epochs):\n",
        "        prediction = model(x_train)\n",
        "\n",
        "        cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRhKMt4hZ0Rq",
        "outputId": "923055fd-7d78-4e45-bb81-4f4a9b2987a2"
      },
      "source": [
        "train(model, optimizer, norm_x_train, y_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/20 Cost: 29785.089844\n",
            "Epoch    1/20 Cost: 18906.166016\n",
            "Epoch    2/20 Cost: 12054.673828\n",
            "Epoch    3/20 Cost: 7702.029785\n",
            "Epoch    4/20 Cost: 4925.733398\n",
            "Epoch    5/20 Cost: 3151.632812\n",
            "Epoch    6/20 Cost: 2016.996094\n",
            "Epoch    7/20 Cost: 1291.051270\n",
            "Epoch    8/20 Cost: 826.505249\n",
            "Epoch    9/20 Cost: 529.207397\n",
            "Epoch   10/20 Cost: 338.934174\n",
            "Epoch   11/20 Cost: 217.153564\n",
            "Epoch   12/20 Cost: 139.206757\n",
            "Epoch   13/20 Cost: 89.313782\n",
            "Epoch   14/20 Cost: 57.375465\n",
            "Epoch   15/20 Cost: 36.928429\n",
            "Epoch   16/20 Cost: 23.835773\n",
            "Epoch   17/20 Cost: 15.450401\n",
            "Epoch   18/20 Cost: 10.077809\n",
            "Epoch   19/20 Cost: 6.633700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEdZXZwWZ4BX"
      },
      "source": [
        "cost값이 줄어드는 것을 확인할 수 있다. 만약 우리가 데이터 전처리를 수행하지 않았다면 데이터 최적화에 더 어려움을 겪었을 수도 있다. 특히 ```y_train```의 크기가 커지거나 원소의 값의 차이가 매우 크게 날 때 전처리가 필요하다."
      ]
    }
  ]
}