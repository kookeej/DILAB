{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab08-1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOoSTy9FRgjWKzDTdsCsMGS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kookeej/DILAB/blob/main/7.1-7.7/lab08-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIj9vJrnib-A"
      },
      "source": [
        "Lab08-1 - Perceptron\n",
        "===\n",
        "# 1. Perceptron\n",
        "```perceptron```은 인공신경망의 한 종류다.    \n",
        "**인공신경망**이란, 생물체의 ```neuron```을 본따 만든 신경망이다. 뉴런과 인공신경망의 동작 방식은 매우 유사하다.\n",
        "    \n",
        "![](https://t1.daumcdn.net/cfile/tistory/99EAB2505AE487821C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi1cLrg5jdzN"
      },
      "source": [
        " 초기 ```perceptron```은 ```AND/OR```문제를 해결하기 위해 개발되었다. AND/OR는 하나의 선으로 0과 1을 분류할 수 있다. 따라서 perceptron으로 AND/OR 문제를 해결할 수 있었다.     \n",
        " ![](http://fileservice.slidewiki.org/media/images/25/4083.PNG)\n",
        "    \n",
        "하지만 하나의 퍼셉트론으로는 ```XOR```문제를 해결할 수 없었다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5My8GaJkXux"
      },
      "source": [
        "# 2. XOR Code\n",
        "실제 퍼셉트론을 구현을 해서 XOR 문제가 정말로 해결될 수 없는지 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1clTsxLRkdXy"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlDCwgWok1HF"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWSL4O-tlBQ3"
      },
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)          # XOR dataset\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEKiy22ylUqn"
      },
      "source": [
        "linear = torch.nn.Linear(2, 1, bias=True)\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "model = torch.nn.Sequential(linear, sigmoid).to(device)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abD77yUzljlu"
      },
      "source": [
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MItPk-doluIo",
        "outputId": "b7f555b3-7463-4635-8336-620af87fbb19"
      },
      "source": [
        "# 학습 단계\n",
        "for step in range(10001):\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    if step % 100 == 0:\n",
        "        print(step, cost.item())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.7273974418640137\n",
            "100 0.6931476593017578\n",
            "200 0.6931471824645996\n",
            "300 0.6931471824645996\n",
            "400 0.6931471824645996\n",
            "500 0.6931471824645996\n",
            "600 0.6931471824645996\n",
            "700 0.6931471824645996\n",
            "800 0.6931471824645996\n",
            "900 0.6931471824645996\n",
            "1000 0.6931471824645996\n",
            "1100 0.6931471824645996\n",
            "1200 0.6931471824645996\n",
            "1300 0.6931471824645996\n",
            "1400 0.6931471824645996\n",
            "1500 0.6931471824645996\n",
            "1600 0.6931471824645996\n",
            "1700 0.6931471824645996\n",
            "1800 0.6931471824645996\n",
            "1900 0.6931471824645996\n",
            "2000 0.6931471824645996\n",
            "2100 0.6931471824645996\n",
            "2200 0.6931471824645996\n",
            "2300 0.6931471824645996\n",
            "2400 0.6931471824645996\n",
            "2500 0.6931471824645996\n",
            "2600 0.6931471824645996\n",
            "2700 0.6931471824645996\n",
            "2800 0.6931471824645996\n",
            "2900 0.6931471824645996\n",
            "3000 0.6931471824645996\n",
            "3100 0.6931471824645996\n",
            "3200 0.6931471824645996\n",
            "3300 0.6931471824645996\n",
            "3400 0.6931471824645996\n",
            "3500 0.6931471824645996\n",
            "3600 0.6931471824645996\n",
            "3700 0.6931471824645996\n",
            "3800 0.6931471824645996\n",
            "3900 0.6931471824645996\n",
            "4000 0.6931471824645996\n",
            "4100 0.6931471824645996\n",
            "4200 0.6931471824645996\n",
            "4300 0.6931471824645996\n",
            "4400 0.6931471824645996\n",
            "4500 0.6931471824645996\n",
            "4600 0.6931471824645996\n",
            "4700 0.6931471824645996\n",
            "4800 0.6931471824645996\n",
            "4900 0.6931471824645996\n",
            "5000 0.6931471824645996\n",
            "5100 0.6931471824645996\n",
            "5200 0.6931471824645996\n",
            "5300 0.6931471824645996\n",
            "5400 0.6931471824645996\n",
            "5500 0.6931471824645996\n",
            "5600 0.6931471824645996\n",
            "5700 0.6931471824645996\n",
            "5800 0.6931471824645996\n",
            "5900 0.6931471824645996\n",
            "6000 0.6931471824645996\n",
            "6100 0.6931471824645996\n",
            "6200 0.6931471824645996\n",
            "6300 0.6931471824645996\n",
            "6400 0.6931471824645996\n",
            "6500 0.6931471824645996\n",
            "6600 0.6931471824645996\n",
            "6700 0.6931471824645996\n",
            "6800 0.6931471824645996\n",
            "6900 0.6931471824645996\n",
            "7000 0.6931471824645996\n",
            "7100 0.6931471824645996\n",
            "7200 0.6931471824645996\n",
            "7300 0.6931471824645996\n",
            "7400 0.6931471824645996\n",
            "7500 0.6931471824645996\n",
            "7600 0.6931471824645996\n",
            "7700 0.6931471824645996\n",
            "7800 0.6931471824645996\n",
            "7900 0.6931471824645996\n",
            "8000 0.6931471824645996\n",
            "8100 0.6931471824645996\n",
            "8200 0.6931471824645996\n",
            "8300 0.6931471824645996\n",
            "8400 0.6931471824645996\n",
            "8500 0.6931471824645996\n",
            "8600 0.6931471824645996\n",
            "8700 0.6931471824645996\n",
            "8800 0.6931471824645996\n",
            "8900 0.6931471824645996\n",
            "9000 0.6931471824645996\n",
            "9100 0.6931471824645996\n",
            "9200 0.6931471824645996\n",
            "9300 0.6931471824645996\n",
            "9400 0.6931471824645996\n",
            "9500 0.6931471824645996\n",
            "9600 0.6931471824645996\n",
            "9700 0.6931471824645996\n",
            "9800 0.6931471824645996\n",
            "9900 0.6931471824645996\n",
            "10000 0.6931471824645996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGleHznmmm43"
      },
      "source": [
        "* cost값이 제대로 감소하고 있지 않다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09dpulxlmC39",
        "outputId": "7a30790d-c91e-4d18-bdf9-2e48e3c8ef03"
      },
      "source": [
        "# 테스트 단계\n",
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print(\"\\nHypothesis: \", hypothesis.detach().cpu().numpy(), '\\nCorrect:', predicted.detach().cpu().numpy(), '\\nAccuracy:', accuracy.item())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Hypothesis:  [[0.5]\n",
            " [0.5]\n",
            " [0.5]\n",
            " [0.5]] \n",
            "Correct: [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]] \n",
            "Accuracy: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg9G2afNmqrO"
      },
      "source": [
        "* 정확도가 0.5이다. 나쁜 성능을 보인다.\n",
        "* 따라서 단 한개의 퍼셉트론만으로는 XOR문제를 해결할 수 없다."
      ]
    }
  ]
}