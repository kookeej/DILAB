{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab11-1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOqCJ9jsY6KYuhnj0WTX2L2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kookeej/DILAB/blob/main/7.8-7.21/Lab11-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8uMXwIlKSUy"
      },
      "source": [
        "Lab11-1 - RNN Basic\n",
        "===\n",
        "## 목차\n",
        "1. RNN의 구조\n",
        "\n",
        "# 1. RNN의 구조\n",
        "* ```sequential data```를 잘 다루기 위해 도입되었다.\n",
        "* ```sequential data```란, 데이터의 값 뿐만 아니라 데이터의 순서도 중요한 의미를 갖는 데이터를 말한다.\n",
        "* 즉, RNN에서는 데이터의 순서도 데이터 정보의 일부분이라고 볼 수 있다.\n",
        "* ```RNN```에서는 입력받는 데이터의 순서를 모델이 어떻게 잘 이해할 수 있을지를 중심으로 설계되어있다.\n",
        "* 보통 아래와 같은 이미지처럼 나타나있다.    \n",
        "\n",
        "![](https://blog.kakaocdn.net/dn/b6bGN9/btqwBY5rg0B/IfSW54Et5Ru9POi7ezLUz0/img.png)     \n",
        "* A라는 셀에 t번째 입력값이 Xt가 들어가게 되면, t번째 출력값 ht가 나오게된다. \n",
        "* 동시에 다른 출력값이 셀 A로부터 나와서 다시 셀 A로 들어간다.\n",
        "* 좌변 그림의 loop를 펼치면 우변 그림과 같다.  \n",
        "* 이렇게 출력되지 않고 다음 셀로 전달되는 값을 ```hidden state```라고 한다. ```hidden state```로 유통되는 값들은 밖에서 보이지 않는다.\n",
        "* 따라서 다음 셀에서는 전 단계의 처리 결과를 반영하게 된다.\n",
        "* RNN은 모든 셀이 파라미터를 공유한다. 즉 셀 A는 하나다. 긴 sequence가 입력되어도 이것을 처리하는 셀은 A 하나다.\n",
        "* 우리는 셀 A의 파라미터만 알고 있다면 다음 단어가 무엇인지 정상적으로 예측할 수 있다.\n",
        "\n",
        "## 1.1. 셀 A에서는 무슨 일이 일어날까?\n",
        "셀 A는 기본적으로 함수연산이다. 셀 A에서의 함수는 기본적으로 **전 단계의 hidden state**와 **지금 단계의 입력값**을 가지고 출력값을 낸다. ```tanh```는 활성화 함수다.    \n",
        "\n",
        "![](https://mblogthumb-phinf.pstatic.net/MjAyMDA0MDRfMzYg/MDAxNTg1OTk0MTY3Mjk0.sxmp8IIxXR-IHqv4X3qdnn45Co-Xp9v2FaSjdhJHAesg.34P0v5EWMDhXMsp1WS0VLtiZPaSUIVQ3MQ0X3vmF7vMg.PNG.riverrun17/image.png?type=w800)\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Hyperbolic_Tangent.svg/2560px-Hyperbolic_Tangent.svg.png)    \n",
        "\n",
        "```LSTM```과 ```GRU```가 유명한 설계들이다.    \n",
        "셀 A에서 A의 파라미터들은 학습의 대상이기 때문에 셀 구조가 복잡해질수록 학습되는 정도는 감소한다.셀의 복잡도는 일반적인 RNN이 가장 낮고 LSTM이 높으며 GRU는 그 중간 쯤에 있다.    \n",
        "\n",
        "![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSGqjBJEJhX7AdtRgQJRfM7700dLQhEMSOvkg&usqp=CAU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqgbtgxYQTbD"
      },
      "source": [
        "# 2. RNN의 사용\n",
        "![](https://goodboychan.github.io/images/copied_from_nb/image/various_rnn.png)    \n",
        "* ```one to one```은 RNN이 아니고 일반적인 Neural Network이다. \n",
        "* ```one to many```는 입력값은 하나고 출력값은 여러개다. 예를 들어 하나의 이미지가 들어가고 여러 단어들의 시퀀스, 즉 문장이 나온다고 가정해보자. 이미지에 일어나고 있는 상황에 대한 설명이 자막으로 달릴 것이다.\n",
        "* ```many to one```은 입력값이 여러개이고 출력값은 하나다. 예를 들어 문장이 입력된다면 그 문장에 대한 감정 레이블을 출력시켜준다고 해보자. 해당 문장에 대한 감정 분석을 해줄 것이다. \n",
        "* ```many to many```은 입력값과 출력값이 모두 여러개다. 두 가지의 모델이 있는데 이 두 모델은 출력되는 지점이 다르다. 먼저 왼쪽 모델은 입력된 문장이 다 끝난 시점부터 다음 문장이 시작된다. 이 모델은 주로 번역 task에 사용된다. 문장을 끝까지 본 뒤에 제대로된 번역이 이루어질 수 있다. 오른쪽 모델은 주로 비디오 task에서 사용된다. 주로 영상에서 어떤 변화가 있었는지를 인식하고 그것에 대한 분석결과를 내놓을 수 있다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4V5yFFkUwzE"
      },
      "source": [
        "# 3. RNN in Pytorch\n",
        "pytorch에서 RNN을 구동하기 위해서는 아래 두 줄이 전부다.\n",
        "```\n",
        "rnn = torch.nn.RNN(input_size, hidden_size)\n",
        "outputs, _status = rnn(input_data)\n",
        "```\n",
        "여기서 input_data는 3개의 차원을 가지는 tensor로 정의된다.     \n",
        "```\n",
        "shape=(?, ?, ?)\n",
        "```\n",
        "첫번째 줄 ```rnn = torch.nn.RNN(input_size, hidden_size```는 셀 A를 선언하는 과정, 두번째 줄 ```outputs, _status = rnn(input_data)```는 input_data인 Xt를 셀 A에 집어넣고, 결과물로 ht를 반환받는 과정이라고 보면 된다.     \n",
        "이 두 줄 전에 코드들도 존재하는데, 이 코드들은 RNN을 사용하기 위해 데이터들을 텐서로 만들어주는 과정에 해당한다. 파이토치에서는 RNN을 사용하기 위해 정해진 규칙에 따라 조작해줘야한다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxz_s7NTYFcO"
      },
      "source": [
        "## 3. Example\n",
        "### 3.1. Input\n",
        "\"hello\"를 RNN에 입력하는 과정이다.    \n",
        "![](https://mblogthumb-phinf.pstatic.net/MjAxOTA3MDlfOSAg/MDAxNTYyNjg0MjgxNzcw.mStzC8__QBRNaPy7h5AZ7w0cj73XJL8meBPvqReR05Mg.MvxChCREVoaduNAfN7Qfa6kIW8dnfxLwLb7nwbzox3og.PNG.hongjg3229/image.png?type=w800)    \n",
        "\n",
        "문자를 모델이 인식할 수 있도록 벡터로 치환해서 RNN으로 전달해준다. 여기서는 ```one-hot encoding```을 사용해서 벡터로 만들어줬다. 여기서 'h'라는 하나의 단어를 표현하기 위해서는 4개의 차원을 갖는 벡터가 필요하다. 4개의 차원을 input으로 받는다는 의미로 **input_size = 4**가 된다.    \n",
        "만약 word embedding 방식을 사용한다면 embedding vector의 차원이 input_size가 된다.     \n",
        "이 input_size는 A가 선언될 때, 사용자가 셀 A에게 미리 알려줘야하는 값이다. 따라서 input_data의 shape=(-, -, 4)가 된다.\n",
        "\n",
        "### 3.2. Hidden State\n",
        "```output data```에 관련된 내용이다. output 데이터로 몇 개의 차원을 가진 벡터로 출력받을지를 결정해주는 과정이다. 어떤 사이즈의 출력을 원하는지에 따라 hidden_size를 정해주면 된다. 만약 우리가 추론하고자 하는 감정의 개수가 2개라면 출력 레이블은 모두 2개가 되고 그 수가 hidden_size가 될 것이다. \n",
        "\n",
        "### 3.3. Sequence Length\n",
        "RNN을 펼쳐보면 X0~Xt까지의 입력 데이터가 존재하는데, 이 t+1개의 입력데이터의 개수가 ```sequence length```다. 만약 \"hello\"라는 입력데이터가 존재한다면 sequence length는 5가 된다.    \n",
        "\n",
        "![](https://blog.kakaocdn.net/dn/bEjt4l/btqC219hIvj/nVGw9gd5FCZJyscwB4tZK1/img.png)    \n",
        "\n",
        "하지만 Pytorch는 사용자가 직접 sequence length를 모델에게 알려주지 않아도 모델이 sequence length를 알아서 자동으로 파악한다. 따라서 별도로 모델에게 length를 전달해주는 과정은 생략된다. \n",
        "\n",
        "### 3.4. Batch Size\n",
        "여러개의 데이터를 하나의 batch로 묶어서 모델에게 학습시킬 수 있다. 예를 들어 h, e, l, o로 이루어진 단어를 세 단어로 묶어서 하나의 배치로 구성한다.\n",
        "```\n",
        "[h,e,l,l,o]\n",
        "[e,o,l,l,l]    ->  set batch input\n",
        "[l,l,e,e,l]\n",
        "```\n",
        "배치 사이즈 역시 사용자가 모델에게 직접 알려주지 않아도 모델에서 자동으로 배치 사이즈를 파악하게 된다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2C2X9Vtn1xu"
      },
      "source": [
        "## 3.5. Full Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE1kUsZRn1Ce"
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0geaX7_pIz1"
      },
      "source": [
        "# 정의\n",
        "input_size = 4\n",
        "hidden_size = 2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRa6lV8KpNW1",
        "outputId": "2d706319-dc1d-45fd-8d8d-3e34d41cbf37"
      },
      "source": [
        "# input data tensor를 만들어주는 과정\n",
        "# one-hot encoding\n",
        "h = [1, 0, 0, 0]\n",
        "e = [0, 1, 0, 0]\n",
        "l = [0, 0, 1, 0]\n",
        "o = [0, 0, 0, 1]\n",
        "input_data_np = np.array([[h, e, l, l, o],          # numpy에서 만들어준 텐서를 torch에서 사용하는 텐서로 바꿔주는 과정\n",
        "                         [e, o, l, l, l],\n",
        "                         [l, l, e, e, l]], dtype=np.float32)\n",
        "\n",
        "# transform as torch tensor\n",
        "input_data = torch.Tensor(input_data_np)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 5, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvTNW06cp9g-"
      },
      "source": [
        "rnn = torch.nn.RNN(input_size, hidden_size)\n",
        "outputs, _status = rnn(input_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvvM5w5oq7BU"
      },
      "source": [
        "# 4. Summary\n",
        "* 파이토치에서는 sequence length와 batch size는 모델이 알아서 파악한다. input_size와 hidden_size만 신경써준다.\n",
        "* 즉, 차원의 구조는 shape = (batch_size, squence length, input_size)다. "
      ]
    }
  ]
}