{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "document_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOBz+Tu/xN6+FoHBbqx1v/7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kookeej/DILAB/blob/main/7.29-8.11/document_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbMuVBNegyuX"
      },
      "source": [
        "문서 분류 (Document Classification)\n",
        "===\n",
        "> *reference: https://www.youtube.com/watch?v=xegxbgsnYko&list=PL7ZVZgsnLwEEoHQAElEPg7l7T6nt25I3N&index=4*\n",
        "# 데이터 준비\n",
        "* 문서 분류에 필요한 데이터는 ```sklearn```이 제공하는 20개의 주제를 가지는 뉴스 그룹을 사용한다.\n",
        "* 텍스트는 `CountVectorizer`를 거쳐 DTM으로 변환한다.\n",
        "* DTM은 문ㅅ에 등장하는 단어들을 빈도수별로 표현한 행렬이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6P_kl_5hM91",
        "outputId": "326cef50-14c1-45c7-c1a9-742b6408f114"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "news = fetch_20newsgroups()\n",
        "\n",
        "x = news.data\n",
        "y = news.target\n",
        "\n",
        "cv = CountVectorizer()\n",
        "x = cv.fit_transform(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(7919, 130107) (7919,) (3395, 130107) (3395,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjbU_f7yh5wN",
        "outputId": "9dd9bc65-12ab-4806-e600-b537dc3efb33"
      },
      "source": [
        "# (0, 56979) 1 -> 0이라는 문서에 56979 인덱스를 갖는 단어가 1번 등장.\n",
        "print(x_train[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 56979)\t1\n",
            "  (0, 85354)\t1\n",
            "  (0, 111322)\t1\n",
            "  (0, 123984)\t1\n",
            "  (0, 68532)\t6\n",
            "  (0, 114731)\t3\n",
            "  (0, 89362)\t3\n",
            "  (0, 76032)\t1\n",
            "  (0, 114579)\t1\n",
            "  (0, 80638)\t3\n",
            "  (0, 114455)\t4\n",
            "  (0, 68766)\t3\n",
            "  (0, 115475)\t12\n",
            "  (0, 32311)\t1\n",
            "  (0, 37433)\t1\n",
            "  (0, 99822)\t1\n",
            "  (0, 66608)\t6\n",
            "  (0, 27436)\t1\n",
            "  (0, 90252)\t3\n",
            "  (0, 128402)\t2\n",
            "  (0, 35983)\t1\n",
            "  (0, 37423)\t1\n",
            "  (0, 56283)\t1\n",
            "  (0, 114494)\t1\n",
            "  (0, 81263)\t2\n",
            "  :\t:\n",
            "  (0, 39072)\t2\n",
            "  (0, 54786)\t1\n",
            "  (0, 46355)\t4\n",
            "  (0, 111149)\t3\n",
            "  (0, 53951)\t2\n",
            "  (0, 85780)\t2\n",
            "  (0, 55212)\t2\n",
            "  (0, 96394)\t1\n",
            "  (0, 52915)\t1\n",
            "  (0, 99238)\t1\n",
            "  (0, 96385)\t1\n",
            "  (0, 96386)\t2\n",
            "  (0, 78602)\t1\n",
            "  (0, 98332)\t1\n",
            "  (0, 27913)\t1\n",
            "  (0, 107491)\t1\n",
            "  (0, 25894)\t1\n",
            "  (0, 60456)\t1\n",
            "  (0, 39203)\t1\n",
            "  (0, 115138)\t1\n",
            "  (0, 51142)\t1\n",
            "  (0, 38170)\t1\n",
            "  (0, 3113)\t1\n",
            "  (0, 10250)\t1\n",
            "  (0, 120286)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEf_wdbziWd5"
      },
      "source": [
        "# scikit-learn을 이용한 문서 분류\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJzd-4rQiaws"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58fSYmh1ifT9"
      },
      "source": [
        "## Logistic Regression\n",
        "* `logistic regression`은 이름에 회귀라는 단어가 들어가지만 클래스의 개수가 2개인 이진 분류를 위한 모델이다.\n",
        "* logistic regression은 linear regression model에 시그모이드 함수를 적용한 것이다.\n",
        "* logistic regression의 학습 목표는 목적 함수인 `BinaryCrossEntropy`를 최소화하는 파라미터 w를 찾는 것이다.\n",
        "* 다중 분류에는 적합하지 않다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK6ljUKbjTJ1",
        "outputId": "ff27cb86-d5bf-4159-b820-6f7b66ce42bf"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR = LogisticRegression()\n",
        "LR.fit(x_train, y_train)\n",
        "pred = LR.predict(x_test)\n",
        "acc = accuracy_score(pred, y_test)      # 예측값과 실제값을 비교하여 정확도를 구한다.\n",
        "print(acc)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8739322533136966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck449f8xjnGu"
      },
      "source": [
        "생각보다 높은 성능이 나왔지만 다중 분류에는 적합하지 않는 모델이기 때문에 logistic regression을 사용하기에는 어려움이 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYpACMotj8AO"
      },
      "source": [
        "## 서포트 벡터 머신(Support Vector Machines)\n",
        "* 회귀(regression), 분류(classification), 이상치 탐지(outlier detection)에 사용된는 지도학습 방법이다.\n",
        "* 클래스 사이의 경계에 위치한 데이터 포인트를 `support vector`라고 한다. \n",
        "* 각 서포트 벡터가 클래스 사이의 `결정 경계`를 구분하는데 얼마나 중요한지를 학습한다.\n",
        "* 각 서포트 벡터 사이의 마진이 가장 큰 방향으로 학습한다. 데이터와 데이터 사이의 거리가 최대가 되도록 학습한다.\n",
        "* 서포트 벡터까지의 **거리**와 서포트 벡터의 **중요도**를 기반으로 예측을 수행한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA-fZLFEkhfK",
        "outputId": "3094de5b-9631-40aa-e188-fae49e6fca46"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "SVM = svm.SVC(kernel='linear')\n",
        "SVM.fit(x_train, y_train)\n",
        "pred = SVM.predict(x_test)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8285714285714286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_nzIzoPk02U"
      },
      "source": [
        "## 나이브 베이스 분류기(Naive Bayes Classification)\n",
        "* 베이즈 정리를 적용한 확률적 분류 알고리즘이다.\n",
        "* 모든 feature들이 독립임을 가정한다. (naive 가정)\n",
        "* 입력 특성에 따라 3개의 분류기가 존재한다.\n",
        "    * 가우시안 나이브 베이즈 분류기\n",
        "    * 베르누이 나이브 베이즈 분류기\n",
        "    * 다항 나이브 베이즈 분류기(DTM 이용)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zjwlGO7ldfT"
      },
      "source": [
        "> ### DTM을 이용한 나이브 베이즈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPEJzXNRlVQM",
        "outputId": "8bbbf16f-1757-4a67-fd8d-a7f194485ee4"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "NB = MultinomialNB()\n",
        "NB.fit(x_train, y_train)\n",
        "pred = NB.predict(x_test)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8206185567010309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRd145WXl0VP"
      },
      "source": [
        "> ### TF-IDF를 이용한 정확도 향상\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXBhCC1rl32o",
        "outputId": "b3bcc19a-232a-4718-da6c-6dd64d54210f"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf = TfidfTransformer()\n",
        "x_train_tf = tfidf.fit_transform(x_train)\n",
        "x_test_tf = tfidf.fit_transform(x_test)\n",
        "\n",
        "NB.fit(x_train_tf, y_train)\n",
        "pred = NB.predict(x_test_tf)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.81620029455081\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgh1SI46mejV"
      },
      "source": [
        "엥 향상 안됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNtbA63RmiEy"
      },
      "source": [
        "## 결정 트리(Decision Tree)\n",
        "* 분류(classification)와 회귀(regression)에 사용되는 지도 학습 방법이다.\n",
        "* 데이터 feature로부터 추론된 결정 규칙을 통해 값을 예측한다.\n",
        "* **if-then-else** 결정 규칙을 통해 데이터를 학습한다.\n",
        "* 트리의 깊이가 깊을수록 복잡한 모델이고 오버피팅이 발생할 위험이 크다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcGm1h02naw2",
        "outputId": "77ce2ce5-6b28-4d57-d4e5-3ffa5a378a08"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "DT = DecisionTreeClassifier()\n",
        "DT.fit(x_train, y_train)\n",
        "pred = DT.predict(x_test)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6329896907216495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHoTAo5spkUH"
      },
      "source": [
        "현재 아무런 처리도 하지 않은 데이터로써는 높은 성능을 기대하기 어렵다. 상당히 좋지 않은 결과가 나왔다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n2oMNnqpxHR"
      },
      "source": [
        "## XGBoot\n",
        "* 트리 기반의 앙상블 기법이다.\n",
        "* 분류에 있어서 다른 알고리즘보다 좋은 예측 성능을 보여준다.\n",
        "* XGBoost는 GBM 기반이지만 GBM의 단점인 느린 수행 시간과 과적합 규제 부재 등의 문제를 해결하였다.\n",
        "* 병렬 CPU 환경에서 빠르게 학습 가능하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LrMQsImps6Q",
        "outputId": "769e3016-2a21-49c4-ca17-141b4f3fe695"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=30, learning_rate=0.05, max_depth=3)\n",
        "xgb.fit(x_train, y_train)\n",
        "pred = xgb.predict(x_test)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7154639175257732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx_vGB54qrmF"
      },
      "source": [
        "단순 Decision Tree보다는 조금 더 좋은 성능이 나왔다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTDhqjWWqeN2"
      },
      "source": [
        "## 교차 검증 (Cross Validation)\n",
        "* 일반 검증은 학습 데이터가 테스트 데이터로 사용되지 않는다.\n",
        "* 교차 검증은 데이터를 n개의 집합으로 나누어 정확도를 계산해 학습 데이터로 사용된 데이터도 테스트 데이터로 사용한다.\n",
        "* 교차 검증을 사용하면 일반 검증보다 **모델의 일반화가 잘 되어있는지** 평가 가능하다.    \n",
        "\n",
        "앞에서 학습시킨 나이브 베이즈 모델을 교차 검증 해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DJ4CY_hrGfj",
        "outputId": "c88dc611-36e5-4171-8393-9b2db4137e90"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(NB, x, y, cv=5)       # 5개의 집합으로 구분\n",
        "print(scores, scores.mean())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.83870968 0.83826779 0.82368537 0.83031374 0.83642794] 0.833480903927519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXhOiwjstWjO"
      },
      "source": [
        "교차검증을 통해 일반 검증보다 좀 더 일반화된 모델을 생성할 수 있다. 하지만 교차 검증은 일반 검증에 비해 n번 검증을 더 하기 때문에 비용이 더 크다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJfd7Dmttjvj"
      },
      "source": [
        "## 정밀도(precision)와 재현율(recall)\n",
        "* `정밀도(precision)`는 양성 클래스(정답)으로 예측한 샘플이 양성 클래스일 확률을 의미한다. 즉, 모델이 얼마나 양성 클래스를 잘 예측하는지를 나타낸다.\n",
        "* `재현율(recall)`은 양성 클래스(정답)인 샘플에서 모델이 양성 클래스로 예측한 샘플 비율을 의미하며, 모델이 얼마나 실제 상황을 재현하는지를 나타낸다.\n",
        "* 정밀도와 재현율의 **가중조화평균인 F1-score**라는 지표는 정확도에 비해 더 효과적인 모델 분석 지표로 알려져 있다.      \n",
        "\n",
        "직접 계산할 수도 있으나 `sklearn`은 이를 편리하게 계산해주는 함수를 제공한다.    \n",
        "\n",
        "* 다중 클래스 분류 문제에서 정밀도와 재현율을 계산할 때는 클래스간의 지표를 어떻게 합칠지 정해야 한다.\n",
        "    * `None`: 클래스간 지표를 합치지 말고 그대로 출력\n",
        "    * `micro`: 정밀도와 재현율이 같음. 이로 인해 f1-score도 정밀도, 재현율과 동일\n",
        "    * `macro`: 클래스간 지표를 단순 평균화한 값\n",
        "    * `weighted`: 클래스간 지표를 가중 평균화한 값\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amB4NJDmv-4X",
        "outputId": "b9cd94bd-d8b6-437d-ea23-156ff0b27c1f"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "precision = precision_score(pred, y_test, average='micro')\n",
        "recall = recall_score(pred, y_test, average='micro')\n",
        "f1 = f1_score(pred, y_test, average='micro')\n",
        "\n",
        "print(precision, recall, f1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7154639175257732 0.7154639175257732 0.7154639175257732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1ViW7DOxFzJ"
      },
      "source": [
        "micro는 정밀도, 재현율, f1-score 보두 같은 값으로 나온다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HUO4FIQv_NB",
        "outputId": "ace2304f-c4e0-4079-fef0-7e08d0d8300d"
      },
      "source": [
        "precision = precision_score(pred, y_test, average='macro')\n",
        "recall = recall_score(pred, y_test, average='macro')\n",
        "f1 = f1_score(pred, y_test, average='macro')\n",
        "\n",
        "print(precision, recall, f1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7116528251239695 0.7449139649401825 0.7215351690399557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luwbpHcxw_j5"
      },
      "source": [
        "# GridSearchCV를 통한 파라미터 최적화\n",
        "`GridSearchCV`는 `Grid Search + Cross Validation`을 뜻한다. 이것을 사용하면 분류기에 사용하는 파라미터 최적화가 가능하다. 또한 교차 검증까지 함께 할 수 있다. 그리그 검색을 통해 앞서 구성한 나이브 베이즈 모델의 'alpha' 파라미터를 최적화시켜보자.\n",
        "\n",
        "* `estimator`: 사용 모델 객체\n",
        "* `param_grid`: 사용 객체. 지정 파라미터 리스트로 구성된 딕셔너리\n",
        "* `scoring`: 최적화하고자 하는 성능 지표\n",
        "* `cv`: 교차 검증 분할 개수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Bka6B6LyDyS",
        "outputId": "8b829b73-b748-4db3-b783-91d673a9fd45"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "gs = GridSearchCV(estimator=NB, param_grid={'alpha': [0.001, 0.01, 0.1, 1.]}, scoring='accuracy', cv=10)\n",
        "gs.fit(x, y)\n",
        "\n",
        "print(gs.best_score_)\n",
        "print(gs.best_params_)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8897820965842167\n",
            "{'alpha': 0.001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87hEuFygyjeZ"
      },
      "source": [
        "성능이 88%까지 증가한 것을 확인할 수 있고 alpha값은 0.001이 최적이 파라미터인 것을 확인할 수 있다."
      ]
    }
  ]
}